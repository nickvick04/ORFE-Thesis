{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/nickvick/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "/Users/nickvick/Library/Python/3.13/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 344MB/s]                     \n",
      "2026-02-05 10:54:04 INFO: Downloaded file to /Users/nickvick/stanza_resources/resources.json\n",
      "2026-02-05 10:54:04 INFO: Downloading default packages for language: en (English) ...\n",
      "2026-02-05 10:54:05 INFO: File exists: /Users/nickvick/stanza_resources/en/default.zip\n",
      "2026-02-05 10:54:06 INFO: Finished downloading models and saved to /Users/nickvick/stanza_resources\n",
      "2026-02-05 10:54:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 41.6MB/s]                    \n",
      "2026-02-05 10:54:06 INFO: Downloaded file to /Users/nickvick/stanza_resources/resources.json\n",
      "2026-02-05 10:54:06 WARNING: Language en package default expects mwt, which has been added\n",
      "2026-02-05 10:54:06 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| mwt          | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2026-02-05 10:54:06 INFO: Using device: cpu\n",
      "2026-02-05 10:54:06 INFO: Loading: tokenize\n",
      "2026-02-05 10:54:07 INFO: Loading: mwt\n",
      "2026-02-05 10:54:07 INFO: Loading: pos\n",
      "2026-02-05 10:54:08 INFO: Loading: constituency\n",
      "2026-02-05 10:54:08 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from convokit import Corpus, download\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# syntactic specific imports\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tree import ParentedTree\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "nltk.download('treebank')\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # pre-trained English model\n",
    "\n",
    "import stanza\n",
    "stanza.download(\"en\")\n",
    "stanza_parser = stanza.Pipeline(\"en\", processors=\"tokenize,pos,constituency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/nickvick/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nickvick/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/nickvick/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nickvick/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# set up for src imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# add project root to sys.path (so src/ can be imported)\n",
    "project_root = os.path.abspath(\"..\")  # adjust if notebooks are nested deeper\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# import required functions\n",
    "from src.data_preprocessing import corpus_to_df, syntactic_preprocessing_df, is_complete_sentence, clean_tokens_lexical, clean_tokens_syntactic, split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/nickvick/.convokit/saved-corpora/subreddit-Cornell\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"subreddit-Cornell\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parented_tree(sentence):\n",
    "    '''Helper function to create a tree for a valid sentence'''\n",
    "\n",
    "    '''if not is_complete_sentence(sentence):\n",
    "        raise ValueError(\"Sentence is not complete\")'''\n",
    "    \n",
    "    doc = stanza_parser(sentence)\n",
    "    stanza_tree = doc.sentences[0].constituency\n",
    "    parented_tree = ParentedTree.fromstring(str(stanza_tree))\n",
    "    \n",
    "    return parented_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_t_units(sentence):\n",
    "\n",
    "    t_unit_count = 0\n",
    "    is_question = False\n",
    "    counted_s_label = False\n",
    "    has_nested_sq_label = False\n",
    "    parent_label = None\n",
    "    to_decremented = False\n",
    "    is_sentence = is_complete_sentence(sentence)\n",
    "\n",
    "    # if a fragment, there are no t-units\n",
    "    if not is_sentence:\n",
    "        return 0\n",
    "    \n",
    "    # create a dependency tree\n",
    "    ptree = create_parented_tree(sentence)\n",
    "\n",
    "    # iterated through parented subtrees\n",
    "    for subtree in ptree.subtrees():\n",
    "\n",
    "        # extract relevant labels\n",
    "        label = subtree.label()\n",
    "        if subtree.parent():\n",
    "            parent_label = subtree.parent().label()\n",
    "\n",
    "        # flag if the sentence is a question and thus has different rules\n",
    "        if label in {\"SQ\", \"SBARQ\"}:\n",
    "             is_question = True\n",
    "             # if we've counted a preceding S label decrement\n",
    "             if counted_s_label:\n",
    "                t_unit_count -= 1\n",
    "                counted_s_label = False\n",
    "\n",
    "        # logic if sentence is a question\n",
    "        if is_question:\n",
    "            if label == \"SQ\":\n",
    "                t_unit_count += 1\n",
    "                # if nested SQ label, flag\n",
    "                if parent_label == \"SQ\":\n",
    "                    has_nested_sq_label = True\n",
    "\n",
    "        # logic when sentence is not a question\n",
    "        else:\n",
    "            # subtract occurences when \"to\" is considered a new subject\n",
    "            if label == \"TO\" and not to_decremented:\n",
    "                t_unit_count -= 1\n",
    "                to_decremented = True\n",
    "                    \n",
    "            # check for subjects in regular sentences\n",
    "            if label == \"S\":\n",
    "                # if subject belongs to subordinate clause, ignore\n",
    "                if parent_label == \"SBAR\":\n",
    "                    continue\n",
    "                # otherwise increment\n",
    "                counted_s_label = True\n",
    "                t_unit_count += 1\n",
    "    \n",
    "    # ignore duplicated subject labels\n",
    "    if t_unit_count > 1 and not is_question:\n",
    "        t_unit_count -= 1\n",
    "    if has_nested_sq_label:\n",
    "        t_unit_count -= 1\n",
    "\n",
    "    # adjust for inappropriate decrements\n",
    "    if t_unit_count == 0:\n",
    "        if to_decremented:\n",
    "            t_unit_count += 1\n",
    "\n",
    "    # heuristic for special constructions\n",
    "    if t_unit_count == 0 and is_sentence:\n",
    "        return 1\n",
    "\n",
    "\n",
    "    return t_unit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clauses(sentence):\n",
    "\n",
    "    clause_count = 0\n",
    "\n",
    "    # only consider complete sentences\n",
    "    if not is_complete_sentence(sentence):\n",
    "        return 0\n",
    "    \n",
    "    t_unit_count = count_t_units(sentence)\n",
    "\n",
    "    # create a dependency tree\n",
    "    ptree = create_parented_tree(sentence)\n",
    "    # print(TreePrettyPrinter(ptree))\n",
    "\n",
    "    # iterated through parented subtrees\n",
    "    for subtree in ptree.subtrees():\n",
    "        # if subject belongs to subordinate clause, increment \n",
    "        if subtree.label() == \"SBAR\":\n",
    "            clause_count += 1\n",
    "\n",
    "    return clause_count + t_unit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_unit_lengths(sentence):\n",
    "    '''Computes the average t-unit length (i.e., the number of words divided by number of t-units)'''\n",
    "\n",
    "    # only consider complete sentences\n",
    "    if not is_complete_sentence(sentence):\n",
    "        return 0\n",
    "\n",
    "    tokens = clean_tokens_lexical(sentence)\n",
    "    num_words = len(tokens)\n",
    "\n",
    "    num_t_units = count_t_units(sentence)\n",
    "\n",
    "    return num_words / num_t_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_ratio(text):\n",
    "    '''Function to determine the ratio of fragments to lines in a given text'''\n",
    "\n",
    "    sentences = split_sentences(text)\n",
    "    total = len(sentences)\n",
    "    if total == 0:\n",
    "        return None\n",
    "\n",
    "    # add complete sentences to a list\n",
    "    is_complete = []\n",
    "    for sent in sentences:\n",
    "        if is_complete_sentence(sent):\n",
    "            is_complete.append(sent)\n",
    "\n",
    "    num_fragment = total - len(is_complete)\n",
    "\n",
    "    fragment_ratio = num_fragment/total\n",
    "\n",
    "    return fragment_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_syntactic_vals(df):\n",
    "    '''Function to compute the syntactic metrics for each utterance in a dataframe.'''\n",
    "\n",
    "    avg_t_units_list = []\n",
    "    clause_t_unit_ratio_list = []\n",
    "    avg_t_unit_length_list = []\n",
    "\n",
    "    for utterance_sentences in tqdm(df[\"final\"]):\n",
    "\n",
    "        # utterance level initializations\n",
    "        total_t_units = 0\n",
    "        total_t_unit_length = 0\n",
    "\n",
    "        # list of values for each sentence in a given utterance\n",
    "        t_units_per_sent = [count_t_units(s) for s in utterance_sentences]\n",
    "        clauses_per_sent = [count_clauses(s) for s in utterance_sentences]\n",
    "\n",
    "        # sum of values for the entire utterance\n",
    "        t_units_per_utterance = sum(t_units_per_sent)\n",
    "        clause_count_per_utterance = sum(clauses_per_sent)\n",
    "\n",
    "\n",
    "        for s in utterance_sentences:\n",
    "            lengths = t_unit_lengths(s)\n",
    "            total_t_unit_length += sum(lengths)\n",
    "            total_t_units += len(lengths)\n",
    "\n",
    "        if total_t_units == 0:\n",
    "            avg_t_unit_len = 0\n",
    "        else:\n",
    "            avg_t_unit_len = total_t_unit_length / total_t_units\n",
    "\n",
    "            \n",
    "\n",
    "        if t_units_per_utterance == 0 or sum(t_unit_lengths_per_sent) == 0:\n",
    "            avg_t_units_list.append(0)\n",
    "            clause_t_unit_ratio_list.append(0)\n",
    "            avg_t_unit_length_list.append(0)\n",
    "            continue\n",
    "\n",
    "        # average per utterance\n",
    "        avg_t_units = t_units_per_utterance / len(t_units_per_sent)\n",
    "        avg_clause_t_unit_ratio = clause_count_per_utterance / t_units_per_utterance\n",
    "        avg_t_unit_len = sum(t_unit_lengths_per_sent) / len(t_unit_lengths_per_sent)\n",
    "\n",
    "        # store values for the current utterance\n",
    "        avg_t_units_list.append(avg_t_units)\n",
    "        clause_t_unit_ratio_list.append(avg_clause_t_unit_ratio)\n",
    "        avg_t_unit_length_list.append(avg_t_unit_len)\n",
    "\n",
    "    # store all values in dataframe\n",
    "    df[\"avg_t_units\"] = avg_t_units_list\n",
    "    df[\"clause_to_t_unit_ratio\"] = clause_t_unit_ratio_list\n",
    "    df[\"avg_t_unit_length\"] = avg_t_unit_length_list\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickvick/Library/CloudStorage/OneDrive-PrincetonUniversity/ORFE/Thesis/ORFE-Thesis/src/data_preprocessing.py:335: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df[\"text\"].str.contains(BOT_TEXT_RE, regex=True)]\n"
     ]
    }
   ],
   "source": [
    "df = corpus_to_df(corpus)\n",
    "df = syntactic_preprocessing_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/65796 [00:03<36:29:29,  2.00s/it]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompute_syntactic_vals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mcompute_syntactic_vals\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# average per utterance\u001b[39;00m\n\u001b[32m     16\u001b[39m avg_t_units = \u001b[38;5;28msum\u001b[39m(t_units_per_sent) / \u001b[38;5;28mlen\u001b[39m(t_units_per_sent)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m avg_clause_t_unit_ratio = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclauses_per_sent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt_units_per_sent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m avg_t_unit_len = \u001b[38;5;28msum\u001b[39m(t_unit_lengths_per_sent) / \u001b[38;5;28mlen\u001b[39m(t_unit_lengths_per_sent)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# store values for the current utterance\u001b[39;00m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "compute_syntactic_vals(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
