{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bca17789",
   "metadata": {},
   "source": [
    "\\setcounter{secnumdepth}{0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e249393",
   "metadata": {},
   "source": [
    "## Quantifying Syntactic Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c707221",
   "metadata": {},
   "source": [
    "To quantify syntactic quality, I will rely on the following metrics, the rationale for which can be found in my thesis report:\n",
    "<br>\n",
    "\n",
    "1. Average number of T-units per sentence\n",
    "2. Ratio of clauses to T-units\n",
    "3. Average T-unit length\n",
    "4. Fragment ratio\n",
    "\n",
    "In choosing these metrics, I successfully capture run-on frequency, clausal complexity, and sentence fragment frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f357df9",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d8236e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\nv9344\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "C:\\Users\\nv9344\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\nv9344\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\triton\\windows_utils.py:404: UserWarning: Failed to find CUDA.\n",
      "  warnings.warn(\"Failed to find CUDA.\")\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 9.18MB/s]                    \n",
      "2025-12-11 16:10:13 INFO: Downloaded file to C:\\Users\\nv9344\\stanza_resources\\resources.json\n",
      "2025-12-11 16:10:13 INFO: Downloading default packages for language: en (English) ...\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/default.zip: 100%|██████████| 526M/526M [00:04<00:00, 117MB/s]  \n",
      "2025-12-11 16:10:18 INFO: Downloaded file to C:\\Users\\nv9344\\stanza_resources\\en\\default.zip\n",
      "2025-12-11 16:10:21 INFO: Finished downloading models and saved to C:\\Users\\nv9344\\stanza_resources\n",
      "2025-12-11 16:10:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 435kB [00:00, 8.55MB/s]                    \n",
      "2025-12-11 16:10:21 INFO: Downloaded file to C:\\Users\\nv9344\\stanza_resources\\resources.json\n",
      "2025-12-11 16:10:21 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-12-11 16:10:21 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| mwt          | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2025-12-11 16:10:21 INFO: Using device: cpu\n",
      "2025-12-11 16:10:21 INFO: Loading: tokenize\n",
      "2025-12-11 16:10:22 INFO: Loading: mwt\n",
      "2025-12-11 16:10:22 INFO: Loading: pos\n",
      "2025-12-11 16:10:23 INFO: Loading: constituency\n",
      "2025-12-11 16:10:24 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from convokit import Corpus, download\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "# syntactic specific imports\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tree import *\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
    "nltk.download('treebank')\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # pre-trained English model\n",
    "\n",
    "import stanza\n",
    "stanza.download(\"en\")\n",
    "stanza_parser = stanza.Pipeline(\"en\", processors=\"tokenize,pos,constituency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362c665",
   "metadata": {},
   "source": [
    "## Syntactic Helper Functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68f1023c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b98f7f",
   "metadata": {},
   "source": [
    "## Lexical Analysis Functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10d26f5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7246720e",
   "metadata": {},
   "source": [
    "## Corpus Selection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "582aa9e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4efcca8",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
