{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying Linguistic Degeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I have the data, I must think about how to quantify linguistic degeneration. For this, I will be using the following metrics:\n",
    "<br>\n",
    "\n",
    "***Lexical Quality***\n",
    "\n",
    "1. Type-token ratio (TTR): measures vocabulary diversity\n",
    "2. Zipf curve tail heaviness: measures use of rare words\n",
    "3. Average word length: measures use of larger words\n",
    "4. Age of acquisition: measures word difficulty\n",
    "\n",
    "***Syntactic Quality***\n",
    "\n",
    "5. Parse tree depth: measures sentence complexity\n",
    "6. Fragment ratio: measure of informality\n",
    "7. Index of Syntactic Complexity: measures overall syntactic quality\n",
    "\n",
    "***Orthographical Quality***\n",
    "\n",
    "8. Levenshtein distance to dictionary: spelling errors\n",
    "9. Punctuation frequency: attention to grammar\n",
    "\n",
    "***Substantive Quality***\n",
    "\n",
    "10. Abstract concepts\n",
    "11. Figurative language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I do not use other traditional measures of lexical complexity, such as ambiguity, vague quantifier frequency, orthographic neighborhood size, terminology inconsistency. Word ambiguity almost exclusively measures the complexity of the text from the perspective of the reader. As the purpose of this analysis is to look at language degeneration over time as a result of modern phenomena, I am principally interested in the intellect required to produce the complexity, meaning I am looking at true substantive complexity as opposed to inteprative complexity. Similarly, vague quantifier frequency, orthographic neighborhood size, and terminology inconsistency also measure complexity of interpratation, hence they are excluded. It is also worth noting that I categorize abstract concepts and figurative language under substantive quality as opposed to lexical complexity, as they involve more intimately the meaning of the word.\n",
    "\n",
    "Likewise, I exclude certain measures of syntactic complexity, such as sentence length, information overload, passive voice, and negation. In the case of sentence length, it can be a sign of high (i.e., complexity) or low (i.e., run-on sentences) quality writing, which is why I have excluded it. Additionally, sentence complexity can be better measured via ICS. Information overload, passive voice, and negation are excluded for the same interpratability versus quality distinction in the above paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Lexical Quality Metrics With Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordfreq import zipf_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''Helper function to tokenize a string of text, removing non-alphabetic characters'''\n",
    "    \n",
    "    text = text.lower()\n",
    "    processed = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = processed.split()\n",
    "\n",
    "    return tokens\n",
    "\n",
    "example = \"Nicholas $%#! @@is# $@! 123 gre4at.ðŸ‘\"\n",
    "print(example)\n",
    "print(tokenize(example))\n",
    "print('The result should only contain words\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/nickvick/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up nltk tokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now try the advanced tokenizer\n",
      "Nicholas is great. Hopefully this works. I now have hope.\n",
      "['Nicholas', 'is', 'great', '.', 'Hopefully', 'this', 'works', '.', 'I', 'now', 'have', 'hope', '.']\n"
     ]
    }
   ],
   "source": [
    "print('Now try the advanced tokenizer')\n",
    "another_example = \"Nicholas is great. Hopefully this works. I now have hope.\"\n",
    "print(another_example)\n",
    "print(word_tokenize(another_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttr(text):\n",
    "    '''Function that returns the type-token ratio'''\n",
    "\n",
    "    tokens = tokenize(text)\n",
    "\n",
    "    # error handling for when there are no tokens\n",
    "    if len(tokens) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # recall that TTR is number of unique words / number of words\n",
    "    num_types = len(set(tokens))\n",
    "    num_tokens = len(tokens)\n",
    "    ttr = num_types / num_tokens\n",
    "\n",
    "    return ttr\n",
    "\n",
    "example2 = \"Nicholas is Nicholas\"\n",
    "print(ttr(example2))\n",
    "print('The result should be 0.66')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(text):\n",
    "    '''Function that determines the average word length of a given text'''\n",
    "    \n",
    "    tokens = tokenize(text)\n",
    "\n",
    "    # error handling for when there are no tokens\n",
    "    if len(tokens) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    average_length = np.mean([len(word) for word in tokens])\n",
    "\n",
    "    return average_length\n",
    "\n",
    "print(avg_word_length(example))\n",
    "print('The result should be 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build aoa_dict: word -> average age of acquisition\n",
    "aoa_df = pd.read_csv(\"Data/KupermanAoAData.csv\")\n",
    "aoa_dict = dict(zip(aoa_df[\"word\"], aoa_df[\"rating_mean\"]))\n",
    "\n",
    "def aoa_score(text, aoa_dict):\n",
    "    '''Returns the average age of acquisition score for a given text'''\n",
    "    \n",
    "    tokens = tokenize(text)\n",
    "    aoa_values = [aoa_dict[word] for word in tokens if word in aoa_dict]\n",
    "\n",
    "    # if there are no words, return a default value\n",
    "    if len(aoa_values) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    aoa_score = np.mean(aoa_values)\n",
    "\n",
    "    return aoa_score\n",
    "\n",
    "example3 = \"because I am cool\"\n",
    "print(aoa_score(example3, aoa_dict))\n",
    "print('This result should be lower than:')\n",
    "example4 = \"sophisticated technical jargon\"\n",
    "print(aoa_score(example4, aoa_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipf_score(text):\n",
    "    '''Returns a frequency score (higher -> more frequent) based on the Zipf scale'''\n",
    "    \n",
    "    tokens = tokenize(text)\n",
    "    zipf_values = [zipf_frequency(word, 'en') for word in tokens]\n",
    "\n",
    "     # if there are no words, return a default value\n",
    "    if len(zipf_values) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    zipf_score = np.mean(zipf_values)\n",
    "\n",
    "    return zipf_score\n",
    "\n",
    "print(zipf_score(example3))\n",
    "print('This result should be higher than:')\n",
    "print(zipf_score(example4))\n",
    "print()\n",
    "\n",
    "example5 = \"word\"\n",
    "print(zipf_score(example5))\n",
    "print('This result should be 5.26')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Syntactic Quality Metrics With Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse-tree depth\n",
    "\n",
    "Fragment ratio\n",
    "\n",
    "Index of Syntactic Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in order to run the following text block, the following must be run to install the relevant NLP model:\n",
    "<br>\n",
    "**python3 -m spacy download en_core_web_sm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # pre-trained English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fragment(text):\n",
    "    '''Helper function to determine whether a sentence is a fragment. Recall that a complete sentence contains at least one subject, \n",
    "    one predicate, one object, and ends with a period. Subjects and objects are almost always nouns, and the predicate is always a verb.\n",
    "    '''\n",
    "    \n",
    "    sentence = nlp(text)\n",
    "    if sentence[0].is_upper\n",
    " \n",
    "    \n",
    "    # check if the root of the dependency parse is a verb or a noun\n",
    "    if sent\n",
    "\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "for sent in doc.sents:\n",
    "    if sent[0].is_uppercase and sent[-1].is_punct:\n",
    "        has_noun = 2\n",
    "        has_verb = 1\n",
    "        for token in sent:\n",
    "            if token.pos_ in [\"NOUN\", \"PROPN\", \"PRON\"]:\n",
    "                has_noun -= 1\n",
    "            elif token.pos_ == \"VERB\":\n",
    "                has_verb -= 1\n",
    "         if has_noun < 1 and has_verb < 1:\n",
    "             print(sent.string.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
